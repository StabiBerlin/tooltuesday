{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "751b7b5e",
   "metadata": {},
   "source": [
    "# NER mit spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16910bb",
   "metadata": {},
   "source": [
    "Eine allererste Zeile code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f48ecefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e61bd9",
   "metadata": {},
   "source": [
    "### spacy importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d718f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40c628",
   "metadata": {},
   "source": [
    "Modell laden (siehe in diesem Fall: https://spacy.io/models/en)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379514fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m nlp=\u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men_core_web_sm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\__init__.py:52\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     29\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     30\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     36\u001b[39m ) -> Language:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\util.py:531\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E050.format(name=name))\n",
      "\u001b[31mOSError\u001b[39m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e719d0",
   "metadata": {},
   "source": [
    "Einen Text definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24fee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Berlin is a city in Germany and the State Library is the national library of a state no longer in existence (Prussia)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9c119",
   "metadata": {},
   "source": [
    "Spacy-pipeline auf den Text anwenden; Ergebnis ist ein sog. Doc Objekt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d001ab7",
   "metadata": {},
   "source": [
    "NER Ergebnisse im Doc Objekt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a678ba",
   "metadata": {},
   "source": [
    "Im Hintergrund läuft dabei eine Spacy-Pipeline; NER ist nur ein (kleiner) Teil dieser \"pipe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01904ad8",
   "metadata": {},
   "source": [
    "Noch einmal auf Deutsch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1358b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Berlin ist eine Stadt in Deutschland. Die Staatsbibliothek zu Berlin ist die Nationalbibliothek eines Staates, den es nicht mehr gibt (Preußen)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0689282",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f82885",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e944e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eine regelbasierte Entity hinzufügen\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "#Liste von Entities und Patterns\n",
    "patterns = [\n",
    "                {\"label\": \"CITY\", \"pattern\": \"Berlin\"},{\"label\": \"ORG\", \"pattern\": \"Staatsbibliothek zu Berlin\"}\n",
    "            ]\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "# entities\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b1fc98",
   "metadata": {},
   "source": [
    "### Visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06021df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent', jupyter='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716651d",
   "metadata": {},
   "source": [
    "### Fontane, *Wanderungen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/fontane_brandenburg01_1862_ch1.txt\") as f:\n",
    "    fontane=f.read()\n",
    "\n",
    "doc = nlp (fontane)\n",
    "\n",
    "# Die ersten 30 entities in unserem ersten Kapitel\n",
    "for ent in doc.ents[:30]:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der ganze Text, visualisiert:\n",
    "displacy.render(doc, style='ent', jupyter='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eaa947",
   "metadata": {},
   "source": [
    "Wir sehen: Das Modell müsste angepasst werden. Das größere Modell in spaCy würde ebenfalls deutlich bessere Ergebnisse liefern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a2c5d",
   "metadata": {},
   "source": [
    "## Ein Modell mit spaCy trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff146035",
   "metadata": {},
   "source": [
    "(Das Folgende basiert auf: W.J.B. Mattingly, Introduction to Named Entity Recognition, 2021 (2nd ed.).  https://ner.pythonhumanities.com/intro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a54f3",
   "metadata": {},
   "source": [
    "Trainingsdaten für spaCy NER müssen im folgenden Format stehen\n",
    "\n",
    "TRAIN_DATA = [ (TEXT AS A STRING, {“entities”: [(START, END, LABEL)]}) ]\n",
    "\n",
    "ACHTUNG: Startindizes beginnen mit \"0\", nicht mit \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5006f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "text = \"Berlin ist eine Stadt in Deutschland. Die Staatsbibliothek zu Berlin ist die Nationalbibliothek eines Staates, den es nicht mehr gibt (Preußen)\"\n",
    "\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "\n",
    "for sent in doc.sents:\n",
    "    corpus.append(sent.text)\n",
    "\n",
    "nlp = spacy.blank(\"de\")\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "patterns = [\n",
    "                {\"label\": \"CITY\", \"pattern\": \"Berlin\"},\n",
    "                {\"label\": \"LOC\", \"pattern\": \"Deutschland\"},\n",
    "                {\"label\": \"ORG\", \"pattern\": \"Staatsbibliothek zu Berlin\"},\n",
    "                {\"label\": \"LOC\", \"pattern\": \"Preußen\"},\n",
    "            ]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "TRAIN_DATA = []\n",
    "for sentence in corpus:\n",
    "    doc = nlp(sentence)\n",
    "    entities = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        entities.append([ent.start_char, ent.end_char, ent.label_])\n",
    "    TRAIN_DATA.append([sentence, {\"entities\": entities}])\n",
    "\n",
    "print (TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "import typer\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "def convert(lang: str, TRAIN_DATA, output_path: Path):\n",
    "    nlp = spacy.blank(lang)\n",
    "    db = DocBin()\n",
    "    for text, annot in TRAIN_DATA:\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is None:\n",
    "                msg = f\"Skipping entity [{start}, {end}, {label}] in the following text because the character span '{doc.text[start:end]}' does not align with token boundaries:\\n\\n{repr(text)}\\n\"\n",
    "                warnings.warn(msg)\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1377337",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(\"de\", TRAIN_DATA, \"data/train.spacy\")\n",
    "convert(\"de\", TRAIN_DATA, \"data/valid.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a074d0ff",
   "metadata": {},
   "source": [
    "Konfigurationsdatei mit SpaCy erstellen: https://spacy.io/usage/training\n",
    "Und die obigen Pfade für Trainings- und Validierungsset nachtragen.\n",
    "\n",
    "Unser Beispiel ist BAD PRACTICE: Das Trainingsset ist natürlich viel zu klein und ist darüber hinaus identisch mit dem Validierungsset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2447ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init fill-config data/base_config.cfg data/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66610bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train data/config.cfg --output ./models/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd61b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_nlp = spacy.load(\"models/output/model-best\")\n",
    "text = \"Berlin ist die Hauptstadt von Deutschland und die Staatsbibliothek von Berlin ist eine große wissenschaftliche Bibliothek.\"\n",
    "doc = trained_nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
